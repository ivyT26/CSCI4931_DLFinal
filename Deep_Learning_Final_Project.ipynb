{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "#libraries to help visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#libraries to shuffle image data\n",
    "import os #used to change directories and make directories\n",
    "import shutil #used to move image samples from directories\n",
    "import random #used to shuffle samples\n",
    "import glob\n",
    "\n",
    "#import another python file we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_1 = [\"Bug\", \"Dark\", \"Dragon\", \"Electric\", \"Fairy\", \"Fighting\", \"Fire\", \"Flying\", \"Ghost\", \"Grass\", \"Ground\", \"Ice\", \"Normal\", \"Poison\", \"Psychic\", \"Rock\", \"Steel\", \"Water\"]\n",
    "type_2 = [\"Bug\", \"Dark\", \"Dragon\", \"Electric\", \"Fairy\", \"Fighting\", \"Fire\", \"Flying\", \"Ghost\", \"Grass\", \"Ground\", \"Ice\", \"None\", \"Normal\", \"Poison\", \"Psychic\", \"Rock\", \"Steel\", \"Water\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the first type water is the largest with 803 files\n",
    "train_type1 = \"CSCI4931_DLFinal-main/Dataset/type1_sorted/train\"\n",
    "test_type1 = \"CSCI4931_DLFinal-main/Dataset/type1_sorted/test\"\n",
    "\n",
    "#For the second type none is the largest with 3,649 files\n",
    "train_type2 = \"CSCI4931_DLFinal-main/Dataset/type2_sorted/train\"\n",
    "test_type2 = \"CSCI4931_DLFinal-main/Dataset/type2_sorted/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read in csv file that has number of files in each folder\n",
    "num_files = pd.read_csv(\"Num_Types.csv\")\n",
    "# print(num_files[\"Type1\"].loc[0:5])\n",
    "type1_num = num_files[\"Type1\"]\n",
    "type2_num = num_files[\"Type2\"] \n",
    "\n",
    "# #threshold number to reach when oversampling (only works for 2 model multilabel classification, need to modify if using one model w/ sigmoid)\n",
    "type1_total = 850\n",
    "type2_total = 3700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do image data augmentation to oversample?: https://www.marktechpost.com/2021/04/05/image-data-augmentation-in-keras/\n",
    "#oversample the data for each train folder\n",
    "#ONLY RUN THIS CELL ONCE\n",
    "os.mkdir(train_type1 + \"/temp/\")\n",
    "\n",
    "temp_path = train_type1 + \"/temp/\"\n",
    "\n",
    "#random oversampling of Pokemon's primary type \n",
    "#same process for each type where random sampling of images is generated and moved into specified folder\n",
    "#process needs to be done so that there are equal distribution of data\n",
    "\n",
    "#random oversampling for type Bug\n",
    "bug_needed = type1_total - type1_num.loc[0]\n",
    "for i in range(0, bug_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Bug/*\"), 1) #only chooses images from bug folder\n",
    "    parsedString = img[0].split('.')\n",
    "#     print(parsedString)\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "#     print(img_name)\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1] #want to save duplicates in separate folder, don't want random sample to choose out of bigger pool that includes duplicates\n",
    "    #also need to rename duplicates so that they can be saved in the same folder \n",
    "#     print(new_img)\n",
    "    shutil.copy(img[0], new_img) #copy duplicate to temp folder\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "#https://www.tutorialspoint.com/How-to-move-a-file-from-one-folder-to-another-using-Python\n",
    "dest_folder = train_type1 + \"/Bug/\"\n",
    "for dup in os.listdir(temp_path): #iterate through the list of files in the directory chosen\n",
    "    img_path = os.path.join(temp_path, dup) #combine file name and folder path to create absolute path to file\n",
    "    if os.path.isfile(img_path): #check if the path is a regular file (not a folder)\n",
    "#         print(img_path)\n",
    "        shutil.move(img_path, dest_folder) #move duplicates to designated class/type\n",
    "    \n",
    "#random oversampling for type Dark\n",
    "dark_needed = type1_total - type1_num.loc[1]\n",
    "for i in range(0, dark_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Dark/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Dark/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Dragon\n",
    "dragon_needed = type1_total - type1_num.loc[2]\n",
    "for i in range(0, dragon_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Dragon/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Dragon/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Electric\n",
    "electric_needed = type1_total - type1_num.loc[3]\n",
    "for i in range(0, electric_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Electric/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Electric/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Fairy\n",
    "fairy_needed = type1_total - type1_num.loc[4]\n",
    "for i in range(0, fairy_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Fairy/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Fairy/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "    \n",
    "#random oversampling for type Fighting\n",
    "fighting_needed = type1_total - type1_num.loc[5]\n",
    "for i in range(0, fighting_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Fighting/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Fighting/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Fire\n",
    "fire_needed = type1_total - type1_num.loc[6]\n",
    "for i in range(0, fire_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Fire/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Fire/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Flying\n",
    "flying_needed = type1_total - type1_num.loc[7]\n",
    "for i in range(0, flying_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Flying/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Flying/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ghost\n",
    "ghost_needed = type1_total - type1_num.loc[8]\n",
    "for i in range(0, ghost_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Ghost/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Ghost/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Grass\n",
    "grass_needed = type1_total - type1_num.loc[9]\n",
    "for i in range(0, grass_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Grass/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Grass/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ground\n",
    "ground_needed = type1_total - type1_num.loc[10]\n",
    "for i in range(0, ground_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Ground/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Ground/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ice\n",
    "ice_needed = type1_total - type1_num.loc[11]\n",
    "for i in range(0, ice_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Ice/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Ice/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Normal\n",
    "normal_needed = type1_total - type1_num.loc[13]\n",
    "for i in range(0, normal_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Normal/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Normal/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Poison\n",
    "poison_needed = type1_total - type1_num.loc[14]\n",
    "for i in range(0, poison_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Poison/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Poison/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Pyschic\n",
    "psychic_needed = type1_total - type1_num.loc[15]\n",
    "for i in range(0, psychic_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Psychic/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Psychic/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "    \n",
    "#random oversampling for type Rock\n",
    "rock_needed = type1_total - type1_num.loc[16]\n",
    "for i in range(0, rock_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Rock/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Rock/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Steel\n",
    "steel_needed = type1_total - type1_num.loc[17]\n",
    "for i in range(0, steel_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Steel/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Steel/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Water\n",
    "water_needed = type1_total - type1_num.loc[18]\n",
    "for i in range(0, water_needed):\n",
    "    img = random.sample(glob.glob(train_type1 + \"/Water/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type1 + \"/Water/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "os.rmdir(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN THIS CELL ONCE\n",
    "#random oversampling for Pokemon's secondary type\n",
    "os.mkdir(train_type2 + \"/temp/\")\n",
    "\n",
    "temp_path = train_type2 + \"/temp/\"\n",
    "\n",
    "#random oversampling for type Bug\n",
    "bug_needed = type2_total - type2_num.loc[0]\n",
    "for i in range(0, bug_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Bug/*\"), 1) #only chooses images from bug folder\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1] #want to save duplicates in separate folder, don't want random sample to choose out of bigger pool that includes duplicates\n",
    "    #also need to rename duplicates so that they can be saved in the same folder \n",
    "    shutil.copy(img[0], new_img) #copy duplicate to temp folder\n",
    "\n",
    "dest_folder = train_type2 + \"/Bug/\"\n",
    "for dup in os.listdir(temp_path): #iterate through the list of files in the directory chosen\n",
    "    img_path = os.path.join(temp_path, dup) #combine file name and folder path to create absolute path to file\n",
    "    if os.path.isfile(img_path): #check if the path is a regular file (not a folder)\n",
    "        shutil.move(img_path, dest_folder) #move duplicates to designated class/type\n",
    "    \n",
    "#random oversampling for type Dark\n",
    "dark_needed = type2_total - type2_num.loc[1]\n",
    "for i in range(0, dark_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Dark/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Dark/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Dragon\n",
    "dragon_needed = type2_total - type2_num.loc[2]\n",
    "for i in range(0, dragon_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Dragon/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Dragon/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Electric\n",
    "electric_needed = type2_total - type2_num.loc[3]\n",
    "for i in range(0, electric_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Electric/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Electric/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Fairy\n",
    "fairy_needed = type2_total - type2_num.loc[4]\n",
    "for i in range(0, fairy_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Fairy/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Fairy/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "    \n",
    "#random oversampling for type Fighting\n",
    "fighting_needed = type2_total - type2_num.loc[5]\n",
    "for i in range(0, fighting_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Fighting/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Fighting/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Fire\n",
    "fire_needed = type2_total - type2_num.loc[6]\n",
    "for i in range(0, fire_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Fire/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Fire/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Flying\n",
    "flying_needed = type2_total - type2_num.loc[7]\n",
    "for i in range(0, flying_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Flying/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Flying/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ghost\n",
    "ghost_needed = type2_total - type2_num.loc[8]\n",
    "for i in range(0, ghost_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Ghost/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Ghost/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Grass\n",
    "grass_needed = type2_total - type2_num.loc[9]\n",
    "for i in range(0, grass_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Grass/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Grass/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ground\n",
    "ground_needed = type2_total - type2_num.loc[10]\n",
    "for i in range(0, ground_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Ground/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Ground/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Ice\n",
    "ice_needed = type2_total - type2_num.loc[11]\n",
    "for i in range(0, ice_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Ice/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Ice/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type None\n",
    "notype_needed = type2_total - type2_num.loc[12]\n",
    "for i in range(0, notype_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/None/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/None/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Normal\n",
    "normal_needed = type2_total - type2_num.loc[13]\n",
    "for i in range(0, normal_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Normal/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Normal/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Poison\n",
    "poison_needed = type2_total - type2_num.loc[14]\n",
    "for i in range(0, poison_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Poison/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Poison/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Pyschic\n",
    "psychic_needed = type2_total - type2_num.loc[15]\n",
    "for i in range(0, psychic_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Psychic/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Psychic/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "    \n",
    "#random oversampling for type Rock\n",
    "rock_needed = type2_total - type2_num.loc[16]\n",
    "for i in range(0, rock_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Rock/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path+ img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Rock/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Steel\n",
    "steel_needed = type2_total - type2_num.loc[17]\n",
    "for i in range(0, steel_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Steel/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Steel/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "#random oversampling for type Water\n",
    "water_needed = type2_total - type2_num.loc[18]\n",
    "for i in range(0, water_needed):\n",
    "    img = random.sample(glob.glob(train_type2 + \"/Water/*\"), 1)\n",
    "    parsedString = img[0].split('.')\n",
    "    img_name = parsedString[0].split(\"\\\\\")\n",
    "    new_img = temp_path + img_name[1] + \"(\" + str(i) + \").\" + parsedString[1]\n",
    "    shutil.copy(img[0], new_img)\n",
    "\n",
    "dest_folder = train_type2 + \"/Water/\"\n",
    "for dup in os.listdir(temp_path):\n",
    "    img_path = os.path.join(temp_path, dup)\n",
    "    if os.path.isfile(img_path):\n",
    "        shutil.move(img_path,dest_folder)\n",
    "\n",
    "os.rmdir(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data augmentation: https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/\n",
    "#ImageDataGenerator: https://keras.io/api/preprocessing/image/\n",
    "#added data augmentation so that the model does not memorize the data\n",
    "datagen_train = ImageDataGenerator(rotation_range=180,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.4,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             validation_split=0.2,\n",
    "                             preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "                            )\n",
    "datagen_test = ImageDataGenerator(rotation_range=180,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.4,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15300 images belonging to 18 classes.\n",
      "Found 1475 images belonging to 18 classes.\n",
      "Found 70300 images belonging to 19 classes.\n",
      "Found 6783 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = ImageDataGenerator(validation_split=0.2, preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=train_type1, target_size=(64, 64), classes=type_1, batch_size=50, shuffle=True)\n",
    "test_batch = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=test_type1, target_size=(64, 64), classes=type_1, batch_size=10, shuffle=False)\n",
    "#This is for data augmentation. Foramt like this\n",
    "#train_batch = datagen_train.flow_from_directory(directory=train_type1, target_size=(64, 64), classes=type_1, batch_size=50, shuffle=True)\n",
    "#test_batch = datagen_test.flow_from_directory(directory=test_type1, target_size=(64, 64), classes=type_1, batch_size=10, shuffle=False)\n",
    "\n",
    "train_batch2 = ImageDataGenerator(validation_split=0.2, preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "    .flow_from_directory(directory=train_type2, target_size=(64, 64), classes=type_2, batch_size=50, shuffle=True)\n",
    "test_batch2 = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\\\n",
    "   .flow_from_directory(directory=test_type2, target_size=(64, 64), classes=type_2, batch_size=10, shuffle=False)\n",
    "\n",
    "#train_batch2 = datagen_train.flow_from_directory(directory=train_type2, target_size=(64, 64), classes=type_2, batch_size=50, shuffle=True)\n",
    "#test_batch2 = datagen_test.flow_from_directory(directory=test_type2, target_size=(64, 64), classes=type_2, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#visualize data (function is from tensorflow's website)\n",
    "imgs, labels = next(train_batch)\n",
    "\n",
    "def plotImages(arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10,20)) #will only show the first 10 images\n",
    "    axes = axes.flatten()\n",
    "    for img, label in zip(arr, axes): \n",
    "        label.imshow(img)\n",
    "        label.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotImages(imgs)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#visualize data (function is from tensorflow's website)\n",
    "imgs2, labels2 = next(train_batch2)\n",
    "\n",
    "def plotImages(arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10,20)) #will only show the first 10 images\n",
    "    axes = axes.flatten()\n",
    "    for img, label in zip(arr, axes): \n",
    "        label.imshow(img)\n",
    "        label.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotImages(imgs2)\n",
    "print(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (2,2), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters = 64, kernel_size = (3,3),activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (2,2), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters = 128, kernel_size = (3,3),activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 256, kernel_size = (3,3),activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 512, kernel_size = (3,3),activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (2,2), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(units = 18, activation = 'softmax'),\n",
    "])\n",
    "#definitely need to extend, feels like data is being overfitted?\n",
    "#Try AveragePooling2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 6.2529 - accuracy: 0.0495 - mean_squared_error: 0.0670\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 2.8698 - accuracy: 0.0851 - mean_squared_error: 0.0524\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 2.7252 - accuracy: 0.1600 - mean_squared_error: 0.0511\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 2.5686 - accuracy: 0.2219 - mean_squared_error: 0.0495\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 2.3978 - accuracy: 0.2719 - mean_squared_error: 0.0475\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 2.1434 - accuracy: 0.3567 - mean_squared_error: 0.0439\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 2.0319 - accuracy: 0.3927 - mean_squared_error: 0.0421\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 27s 544ms/step - loss: 1.9396 - accuracy: 0.4188 - mean_squared_error: 0.0407\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 1.7749 - accuracy: 0.4681 - mean_squared_error: 0.0376\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 1.5883 - accuracy: 0.5130 - mean_squared_error: 0.0345\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 1.5926 - accuracy: 0.5261 - mean_squared_error: 0.0340\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 1.5066 - accuracy: 0.5387 - mean_squared_error: 0.0334\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 27s 544ms/step - loss: 1.3093 - accuracy: 0.6002 - mean_squared_error: 0.0296\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 1.2614 - accuracy: 0.6164 - mean_squared_error: 0.0278\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.1484 - accuracy: 0.6703 - mean_squared_error: 0.0256\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 1.0216 - accuracy: 0.6937 - mean_squared_error: 0.0233\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.9996 - accuracy: 0.7157 - mean_squared_error: 0.0225\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.8847 - accuracy: 0.7439 - mean_squared_error: 0.0205\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 0.8288 - accuracy: 0.7681 - mean_squared_error: 0.0189\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.7834 - accuracy: 0.7680 - mean_squared_error: 0.0183\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.7479 - accuracy: 0.7792 - mean_squared_error: 0.0175\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 27s 530ms/step - loss: 0.6557 - accuracy: 0.7985 - mean_squared_error: 0.0156\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.6517 - accuracy: 0.8021 - mean_squared_error: 0.0157\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.6219 - accuracy: 0.8203 - mean_squared_error: 0.0147\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.4873 - accuracy: 0.8606 - mean_squared_error: 0.0117\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.4682 - accuracy: 0.8735 - mean_squared_error: 0.0109\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.4558 - accuracy: 0.8595 - mean_squared_error: 0.0111\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.4431 - accuracy: 0.8675 - mean_squared_error: 0.0107\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.3973 - accuracy: 0.8911 - mean_squared_error: 0.0094\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.3437 - accuracy: 0.9009 - mean_squared_error: 0.0085\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 27s 530ms/step - loss: 0.3840 - accuracy: 0.8795 - mean_squared_error: 0.0096\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.3272 - accuracy: 0.9022 - mean_squared_error: 0.0079\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.3196 - accuracy: 0.9002 - mean_squared_error: 0.0080\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.3024 - accuracy: 0.9114 - mean_squared_error: 0.0075\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.2457 - accuracy: 0.9198 - mean_squared_error: 0.0064\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.2108 - accuracy: 0.9359 - mean_squared_error: 0.0052\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.1823 - accuracy: 0.9416 - mean_squared_error: 0.0047\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.2087 - accuracy: 0.9404 - mean_squared_error: 0.0052\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.2412 - accuracy: 0.9300 - mean_squared_error: 0.0060\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.1852 - accuracy: 0.9442 - mean_squared_error: 0.0044\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.2071 - accuracy: 0.9365 - mean_squared_error: 0.0055\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.1602 - accuracy: 0.9540 - mean_squared_error: 0.0039\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.1708 - accuracy: 0.9472 - mean_squared_error: 0.0044\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.1804 - accuracy: 0.9505 - mean_squared_error: 0.0044\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.1472 - accuracy: 0.9574 - mean_squared_error: 0.0038\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.1544 - accuracy: 0.9526 - mean_squared_error: 0.0038\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.1257 - accuracy: 0.9565 - mean_squared_error: 0.0036\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.1717 - accuracy: 0.9552 - mean_squared_error: 0.0039\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.1609 - accuracy: 0.9532 - mean_squared_error: 0.0041\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.1488 - accuracy: 0.9539 - mean_squared_error: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e798ed5e08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batch, steps_per_epoch = 50, epochs = 50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)),\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (2,2), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (3,3), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size = (2,2), strides = 2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(units = 19, activation = 'softmax'),\n",
    "])\n",
    "#definitely need to extend, feels like data is being overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = Adam(learning_rate = 0.0001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brady\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 8.3269 - accuracy: 0.0609 - mean_squared_error: 0.0681\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 2.9339 - accuracy: 0.0999 - mean_squared_error: 0.0498\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 2.7017 - accuracy: 0.1707 - mean_squared_error: 0.0475\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 2.5194 - accuracy: 0.2385 - mean_squared_error: 0.0456\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 2.2616 - accuracy: 0.3092 - mean_squared_error: 0.0424\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 2.1313 - accuracy: 0.3688 - mean_squared_error: 0.0403\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 2.0821 - accuracy: 0.3628 - mean_squared_error: 0.0398\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 1.8609 - accuracy: 0.4417 - mean_squared_error: 0.0365\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 1.6989 - accuracy: 0.4777 - mean_squared_error: 0.0342\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 1.5210 - accuracy: 0.5634 - mean_squared_error: 0.0306\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 1.3743 - accuracy: 0.5752 - mean_squared_error: 0.0287\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 1.2419 - accuracy: 0.6532 - mean_squared_error: 0.0252\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 1.2331 - accuracy: 0.6409 - mean_squared_error: 0.0258\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 1.1109 - accuracy: 0.6824 - mean_squared_error: 0.0233\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 1.0172 - accuracy: 0.7047 - mean_squared_error: 0.0215\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.9322 - accuracy: 0.7255 - mean_squared_error: 0.0203\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.8392 - accuracy: 0.7473 - mean_squared_error: 0.0180\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.7106 - accuracy: 0.7962 - mean_squared_error: 0.0157\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.6589 - accuracy: 0.8063 - mean_squared_error: 0.0146\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.6190 - accuracy: 0.8125 - mean_squared_error: 0.0141\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.6063 - accuracy: 0.8291 - mean_squared_error: 0.0130\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.5545 - accuracy: 0.8323 - mean_squared_error: 0.0126\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.4928 - accuracy: 0.8589 - mean_squared_error: 0.0111\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 0.4807 - accuracy: 0.8611 - mean_squared_error: 0.0106\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.4039 - accuracy: 0.8845 - mean_squared_error: 0.0090\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.4113 - accuracy: 0.8783 - mean_squared_error: 0.0093\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.4213 - accuracy: 0.8760 - mean_squared_error: 0.0095\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.3520 - accuracy: 0.8915 - mean_squared_error: 0.0086\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.3246 - accuracy: 0.9082 - mean_squared_error: 0.0076\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.3111 - accuracy: 0.9071 - mean_squared_error: 0.0074\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 0.2969 - accuracy: 0.9071 - mean_squared_error: 0.0070\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.2373 - accuracy: 0.9366 - mean_squared_error: 0.0053\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 25s 501ms/step - loss: 0.3092 - accuracy: 0.9049 - mean_squared_error: 0.0071\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 26s 510ms/step - loss: 0.2407 - accuracy: 0.9233 - mean_squared_error: 0.0058\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.2328 - accuracy: 0.9255 - mean_squared_error: 0.0056\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 0.1990 - accuracy: 0.9430 - mean_squared_error: 0.0046\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.1835 - accuracy: 0.9436 - mean_squared_error: 0.0044\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.1869 - accuracy: 0.9457 - mean_squared_error: 0.0043\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.2288 - accuracy: 0.9338 - mean_squared_error: 0.0053\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.1961 - accuracy: 0.9397 - mean_squared_error: 0.0047\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.1722 - accuracy: 0.9551 - mean_squared_error: 0.0039\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.1689 - accuracy: 0.9520 - mean_squared_error: 0.0041\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.1982 - accuracy: 0.9399 - mean_squared_error: 0.0047\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 0.1750 - accuracy: 0.9450 - mean_squared_error: 0.0043\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.1757 - accuracy: 0.9506 - mean_squared_error: 0.0040\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.1428 - accuracy: 0.9571 - mean_squared_error: 0.0035\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.1283 - accuracy: 0.9600 - mean_squared_error: 0.0032\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 0.1506 - accuracy: 0.9570 - mean_squared_error: 0.0036\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.1454 - accuracy: 0.9536 - mean_squared_error: 0.0037\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.1404 - accuracy: 0.9521 - mean_squared_error: 0.0036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e799af9cc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=train_batch2, steps_per_epoch = 50, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7453741e-06, 2.0479540e-07, 1.5696694e-04, ..., 2.5541171e-05,\n",
       "        4.6845448e-06, 5.2424198e-06],\n",
       "       [7.2068321e-03, 4.5332959e-04, 2.0980237e-04, ..., 8.5993094e-04,\n",
       "        1.7207592e-05, 9.2295175e-03],\n",
       "       [3.6388243e-05, 2.0117938e-08, 4.4771982e-06, ..., 2.2048125e-06,\n",
       "        9.3832517e-01, 5.7268396e-02],\n",
       "       ...,\n",
       "       [1.3652108e-04, 1.5261669e-09, 2.2095049e-02, ..., 2.6251515e-02,\n",
       "        8.2678431e-05, 8.2123411e-01],\n",
       "       [2.0272047e-03, 4.0508992e-05, 6.2716559e-02, ..., 3.1099737e-06,\n",
       "        1.2947156e-05, 3.9038694e-01],\n",
       "       [2.3642363e-07, 2.0680335e-09, 1.2306012e-07, ..., 2.2649500e-03,\n",
       "        5.0299775e-08, 9.2705915e-05]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.predict(test_batch)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3825600e-01, 1.9972686e-02, 4.7691385e-04, ..., 3.4654749e-05,\n",
       "        2.9111826e-01, 5.0196482e-05],\n",
       "       [9.9999642e-01, 8.3326812e-09, 8.9577892e-09, ..., 4.7881787e-09,\n",
       "        7.9294887e-07, 7.9554155e-11],\n",
       "       [9.7829312e-01, 1.6374881e-07, 1.3757699e-04, ..., 1.3663778e-02,\n",
       "        1.7645906e-04, 4.6226605e-06],\n",
       "       ...,\n",
       "       [1.9617266e-06, 1.1056164e-05, 1.5125020e-05, ..., 3.1729959e-04,\n",
       "        2.9732782e-06, 9.3971854e-01],\n",
       "       [3.3473310e-10, 2.3891703e-04, 2.1510592e-05, ..., 9.9860029e-03,\n",
       "        2.7552440e-08, 9.8652309e-01],\n",
       "       [7.7275336e-10, 5.3264182e-07, 1.3281687e-07, ..., 2.6612390e-06,\n",
       "        3.4025675e-07, 9.9912184e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = model2.predict(test_batch2)\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "prediction2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(pokemon):\n",
    "    return np.argmax(pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(output)):\n",
    "    prediction.append(getType(output[x]))\n",
    "    \n",
    "for x in range(0, len(output2)):\n",
    "    prediction2.append(getType(output2[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 accuracy:\n",
      "57.83050847457627\n",
      "Type 2 accuracy:\n",
      "70.79463364293086\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(prediction, real):\n",
    "    correct = 0\n",
    "    if len(prediction) != len(real):\n",
    "        print(\"Error\")\n",
    "        return 0\n",
    "    for x in range(0, len(prediction)):\n",
    "        if prediction[x] == real[x]:\n",
    "            correct += 1\n",
    "    print(100 * (correct / len(prediction)))\n",
    "\n",
    "print(\"Type 1 accuracy:\")\n",
    "test_accuracy(prediction,test_batch.labels)\n",
    "print(\"Type 2 accuracy:\")\n",
    "test_accuracy(prediction2,test_batch2.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
